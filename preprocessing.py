import pandas as pd
import pandas_ta as ta
from sklearn.preprocessing import MinMaxScaler
from transformers import pipeline
import torch
import numpy as np
from utils import get_device

class Preprocessor:
    def __init__(self):
        self.scaler = MinMaxScaler()
        self.sentiment_analyzer = None
        self.device = 0 if torch.cuda.is_available() else -1

    def add_technical_indicators(self, df):
        """
        Adds technical indicators to the DataFrame using pandas_ta.
        """
        # Ensure 'Close' is present
        if 'Close' not in df.columns:
            # yfinance returns 'Close' with capital C usually.
            # Handle potential case sensitivity or missing data
            if 'close' in df.columns:
                df['Close'] = df['close']
            else:
                raise ValueError("DataFrame must contain 'Close' column")

        # RSI
        df['RSI'] = ta.rsi(df['Close'], length=14)
        
        # MACD
        macd = ta.macd(df['Close'])
        df = pd.concat([df, macd], axis=1)
        
        # EMA
        df['EMA_20'] = ta.ema(df['Close'], length=20)
        df['EMA_50'] = ta.ema(df['Close'], length=50)
        
        # Drop NaN values generated by indicators
        df.dropna(inplace=True)
        return df

    def get_sentiment_score(self, news_items):
        """
        Analyzes sentiment of news items using FinBERT.
        Returns an average sentiment score (-1 to 1).
        """
        if not news_items:
            return 0.0

        if self.sentiment_analyzer is None:
            print("Loading FinBERT model for sentiment analysis...")
            try:
                self.sentiment_analyzer = pipeline("sentiment-analysis", model="ProsusAI/finbert", device=self.device)
            except Exception as e:
                print(f"Error loading FinBERT: {e}. Defaulting to neutral sentiment.")
                return 0.0

        scores = []
        headlines = [item['title'] for item in news_items if 'title' in item]
        
        # Process in batches if necessary, but for now just process all
        # Limit to last 10 headlines to save time
        headlines = headlines[:10] 
        
        if not headlines:
            return 0.0

        results = self.sentiment_analyzer(headlines)
        
        for res in results:
            # Map labels to scores: positive=1, neutral=0, negative=-1
            label = res['label']
            score = res['score']
            
            if label == 'positive':
                final_score = score
            elif label == 'negative':
                final_score = -score
            else:
                final_score = 0
            
            scores.append(final_score)
            
        return sum(scores) / len(scores)

    def prepare_data_for_model(self, df, sentiment_score, seq_length=60):
        """
        Prepares data sequences for the Transformer model.
        Features: Close, Volume, RSI, MACD, EMA. (Sentiment is added as a static feature or concatenated)
        """
        # Feature selection
        # Note: yfinance multi-index columns might need flattening if not done already
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.get_level_values(0)

        cols = ['Close', 'Volume', 'RSI', 'EMA_20'] # Simplified feature set
        # Check if columns exist
        available_cols = [c for c in cols if c in df.columns]
        data = df[available_cols].values
        
        # Scale data
        scaled_data = self.scaler.fit_transform(data)
        
        # Create sequences
        X, y = [], []
        for i in range(len(scaled_data) - seq_length):
            # Sequence of features
            seq_x = scaled_data[i:i+seq_length]
            
            # Target: Close price (index 0) of the *next* step. 
            # We want to predict Close price.
            target = scaled_data[i+seq_length, 0] 
            
            # Augment sequence with sentiment (simple approach: append to every step or just use as context)
            # For simplicity, let's treat sentiment as a separate input or just ignore for the MVP if it complicates shape
            # To integrate sentiment properly, we'd need historical sentiment. 
            # Since we only fetch *current* news, using it for historical training is WRONG.
            # Strategy: We will ONLY use sentiment for the FINAL prediction adjustments or as a separate input at inference.
            # For training *historical* price patterns, we rely on price/tech indicators.
            
            X.append(seq_x)
            y.append(target)
            
        return np.array(X), np.array(y), self.scaler

if __name__ == "__main__":
    # Test
    from data_loader import fetch_stock_data, fetch_news
    df = fetch_stock_data("AAPL", period="1y", interval="1d")
    prep = Preprocessor()
    df = prep.add_technical_indicators(df)
    news = fetch_news("AAPL")
    sentiment = prep.get_sentiment_score(news)
    print(f"Sentiment Score: {sentiment}")
    X, y, scaler = prep.prepare_data_for_model(df, sentiment)
    print(f"X shape: {X.shape}, y shape: {y.shape}")
